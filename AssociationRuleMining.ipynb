{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.ui.proxyBase', '/proxy/application_1638081630762_0004'),\n",
       " ('spark.app.name', 'Lab4'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '/usr/local/spark/python:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip'),\n",
       " ('spark.executor.memory', '4g'),\n",
       " ('spark.driver.port', '33559'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.bindAddress', '192.1.1.11'),\n",
       " ('spark.app.startTime', '1638090766293'),\n",
       " ('spark.ui.port', '4050'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.driver.appUIAddress', 'http://edge:4050'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://yarnmaster:8088/proxy/application_1638081630762_0004'),\n",
       " ('spark.yarn.jars', ''),\n",
       " ('spark.driver.host', 'edge'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.cores.max', '2'),\n",
       " ('spark.app.id', 'application_1638081630762_0004'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'yarnmaster')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setMaster(\"yarn\").setAppName(\"Lab4\")\n",
    "conf.set(\"spark.executor.memory\", \"4g\")\n",
    "conf.set(\"spark.driver.memory\", \"4g\")\n",
    "conf.set(\"spark.cores.max\", \"2\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawRDD = (sc.textFile(\"hdfs://yarnmaster:9000/itemsets_extra\",16))\n",
    "itemsetRDD = rawRDD.map(lambda x: sorted([int(item) for item in x.strip().split(' ')]))\n",
    "freqItemset = itemsetRDD.flatMap(lambda x: set(x)).map(lambda x: (x,1)).reduceByKey(lambda a,b: a+b) \\\n",
    ".filter(lambda x: x[1]>99).map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 1: Find the products which are frequently browsed together by using the A-priori algorithm.\n",
    "\n",
    "freqItemset : candidate for k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqSet = set(freqItemset.collect())\n",
    "def getFreqItemOnly(x):\n",
    "    res = []\n",
    "    for it in x:\n",
    "        if it in freqSet:\n",
    "            res.append(it)\n",
    "    return res\n",
    "\n",
    "freqRDD = itemsetRDD.map(getFreqItemOnly).filter(lambda x: len(x)>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert freqItemset to set for faster element check (I saw the in implementation of paper they even used tree structure)\n",
    "+ Filter out item that not in candidate k=1 and basket that not contains more than 1 item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 ms, sys: 0 ns, total: 21.6 ms\n",
      "Wall time: 56 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((21, 401), 2070),\n",
       " ((21, 529), 2521),\n",
       " ((35, 983), 574),\n",
       " ((54, 460), 1392),\n",
       " ((175, 883), 968)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import itertools\n",
    "pairRDD = freqRDD.flatMap(lambda x: itertools.combinations(x,2))\n",
    "pairCandidate = pairRDD.map(lambda x: (x,1)).reduceByKey(lambda a,b: a+b) \\\n",
    ".filter(lambda x: x[1]>99)\n",
    "pairCandidate.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use itertools to generate combination of candidate pairs in each basket\n",
    "+ simply count and filter out pair that not match support thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqPairItemSet = pairCandidate.flatMap(lambda x: [x[0][0],x[0][1]]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freqPairItemSet: items that appear in frequent pairs candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "........................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFreqItemFromPairOnly(x):\n",
    "    res = []\n",
    "    for it in x:\n",
    "        if it in freqPairItemSet:\n",
    "            res.append(it)\n",
    "    return res\n",
    "\n",
    "\n",
    "freqPairRDD = freqRDD.map(getFreqItemFromPairOnly).filter(lambda x: len(x)>2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out items that not appear in frequent pairs candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 48.9 ms, total: 294 ms\n",
      "Wall time: 57min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((518, 828, 947), 165),\n",
       " ((694, 775, 790), 103),\n",
       " ((272, 510, 579), 645),\n",
       " ((368, 401, 794), 148),\n",
       " ((48, 438, 795), 1185)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tripleRDD = freqPairRDD.flatMap(lambda x: itertools.combinations(x,3))\n",
    "tripleCandidate = tripleRDD.map(lambda x: (x,1)).reduceByKey(lambda a,b: a+b) \\\n",
    ".filter(lambda x: x[1]>99)\n",
    "tripleCandidate.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ generate combinations of 3 in each basket\n",
    "+ count and filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTripletPair(x):\n",
    "    res = []\n",
    "    res.append(((x[0][0],x[0][1]),(x[0][2],x[1])))\n",
    "    res.append(((x[0][0],x[0][2]),(x[0][1],x[1])))\n",
    "    res.append(((x[0][1],x[0][2]),(x[0][0],x[1])))\n",
    "    return res\n",
    "\n",
    "tripleAsso = tripleCandidate.flatMap(genTripletPair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ((x,y,z), value) -> ((x,y),(z,value)), ((x,z),(y,value)), ((y,z),(x,value)) => prepare key for join with pairCandidate\n",
    "+ Only need 3 because x<y<z (sorted at the beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 8.25 ms, total: 111 ms\n",
      "Wall time: 13min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('(259, 848) -> 411', 1.0),\n",
       " ('(289, 586) -> 766', 1.0),\n",
       " ('(717, 766) -> 554', 1.0),\n",
       " ('(529, 880) -> 145', 1.0),\n",
       " ('(781, 916) -> 900', 1.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def genRule(x):\n",
    "    return (str(x[0])+ \" -> \" + str(x[1][0][0]), round(x[1][0][1]/x[1][1],2))\n",
    "            \n",
    "tripleAsso.join(pairCandidate).map(genRule).filter(lambda x:x[1]>0.7).sortBy(lambda x: x[1], ascending=False).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Join with pair candidates\n",
    "+ do the division\n",
    "+ filter out rules that has conf <0.7\n",
    "+ sorting\n",
    "+ get top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
